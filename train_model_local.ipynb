{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5633ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 parquet files → 6126272 rows\n",
      "Kept 61 sessions longer than 3 days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.train import train_loop\n",
    "from src.model import CNNLSTMModel\n",
    "from src.dataset import InverterTimeSeriesDataset\n",
    "from src.preprocess import *\n",
    "import torch\n",
    "\n",
    "inverter_data = load_parquet_data('data/inverter_data')\n",
    "failure_sessions = load_failure_sessions('data/failure_sessions.csv', min_days=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edc7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverter_data = inverter_data[inverter_data['device_name']=='INV 51']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c262cba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pre-failure rows: 82486\n",
      "Total rows: 5905370\n"
     ]
    }
   ],
   "source": [
    "labeled_df = prepare_dataset(inverter_data, failure_sessions)\n",
    "labeled_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89be8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 4724296 Train set time range: 2021-12-02 00:00:00 to 2024-10-27 01:00:00\n",
      "Test set size: 1181074 Test set time range: 2024-10-27 01:00:00 to 2025-07-23 23:35:00\n",
      "Train set size: 590537 Train set time range: 2024-10-27 01:00:00 to 2025-03-04 04:40:00\n",
      "Test set size: 590537 Test set time range: 2025-03-04 04:40:00 to 2025-07-23 23:35:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing devices: 100%|██████████| 16/16 [00:13<00:00,  1.22it/s]\n",
      "Processing devices: 100%|██████████| 16/16 [00:01<00:00,  8.17it/s]\n",
      "Processing devices: 100%|██████████| 16/16 [00:01<00:00,  8.96it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    \"metric.AC_POWER.MEASURED\",\n",
    "#    \"metric.DC_POWER.MEASURED\",\n",
    "#    \"metric.AC_CURRENT_A.MEASURED\",\n",
    "#    \"metric.AC_CURRENT_B.MEASURED\",\n",
    "#    \"metric.AC_CURRENT_C.MEASURED\",\n",
    "#    \"metric.DC_CURRENT.MEASURED\",\n",
    "#    \"metric.DC_CURRENT_AVG.MEASURED\",\n",
    "#    \"metric.DC_CURRENT_MAX.MEASURED\",\n",
    "#    \"metric.FREQUENCY.MEASURED\",\n",
    "#    \"metric.POWER_FACTOR.MEASURED\",\n",
    "#    \"metric.HEARTBEAT.MEASURED\",\n",
    "#    \"metric.COMM_LINK.MEASURED\",\n",
    "#    \"metric.STATUS_WARNING_WORD.MEASURED\",\n",
    "#    \"metric.STATUS_FAULT_WORD.MEASURED\",\n",
    "#    \"metric.STATUS_IGBT_MAX_TEMP.MEASURED\",\n",
    "#    \"metric.STATUS_INTERNAL_TEMP.MEASURED\",\n",
    "#    \"metric.STATUS_INTERNAL_HUMIDITY.MEASURED\"\n",
    "]\n",
    "\n",
    "train_df, test_df = train_test_split_on_time(labeled_df, 0.2)\n",
    "val_df, test_df = train_test_split_on_time(test_df, 0.5)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = InverterTimeSeriesDataset(train_df, feature_cols)\n",
    "val_ds   = InverterTimeSeriesDataset(val_df,   feature_cols)\n",
    "test_ds  = InverterTimeSeriesDataset(test_df,  feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b204cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2**15\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=6, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4316e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTMModel(num_features=len(feature_cols))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d87e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_loop(model,\n",
    "               train_loader: DataLoader,\n",
    "               val_loader: DataLoader = None,\n",
    "               device='cuda',\n",
    "               optimizer=None,\n",
    "               criterion=None,\n",
    "               num_epochs=10,\n",
    "               scheduler=None,\n",
    "               log_interval=100):\n",
    "    \"\"\"\n",
    "    通用 PyTorch 訓練迴圈，適用 CNN+LSTM 二分類模型\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device)\n",
    "    print(f\"Model moved to {device}\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        print(f\"🔁 Starting epoch {epoch}/{num_epochs}\")\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_idx, (X, y) in enumerate(train_loader):\n",
    "            #print(X.shape, y.shape)  # Debugging shape\n",
    "            X = X.to(device, non_blocking=True)  # 建議加 non_blocking=True\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            output = output.squeeze()  # [B] if needed\n",
    "\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(f\"[Epoch {epoch}/{num_epochs}] Step {batch_idx}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(f\"🔁 Epoch {epoch} finished. Avg Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # 驗證階段\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for X_val, y_val in val_loader:\n",
    "                    X_val, y_val = X_val.to(device), y_val.to(device).float()\n",
    "                    output = model(X_val).squeeze()\n",
    "                    val_loss += criterion(output, y_val).item()\n",
    "\n",
    "                    pred = torch.sigmoid(output) > 0.5\n",
    "                    correct += (pred == y_val).sum().item()\n",
    "                    total += y_val.size(0)\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            accuracy = correct / total\n",
    "            print(f\"✅ Validation Loss: {avg_val_loss:.4f} | Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "        # scheduler step if used\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    print(\"🏁 Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c807ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to cuda\n",
      "🔁 Starting epoch 1/10\n",
      "[Epoch 1/10] Step 0/145 - Loss: 0.2636\n",
      "[Epoch 1/10] Step 10/145 - Loss: 0.2244\n",
      "[Epoch 1/10] Step 20/145 - Loss: 0.1674\n",
      "[Epoch 1/10] Step 30/145 - Loss: 0.0791\n",
      "[Epoch 1/10] Step 40/145 - Loss: 0.0224\n",
      "[Epoch 1/10] Step 50/145 - Loss: 0.0155\n",
      "[Epoch 1/10] Step 60/145 - Loss: 0.0148\n",
      "[Epoch 1/10] Step 70/145 - Loss: 0.0152\n",
      "[Epoch 1/10] Step 80/145 - Loss: 0.0136\n",
      "[Epoch 1/10] Step 90/145 - Loss: 0.0136\n",
      "[Epoch 1/10] Step 100/145 - Loss: 0.0127\n",
      "[Epoch 1/10] Step 110/145 - Loss: 0.0134\n",
      "[Epoch 1/10] Step 120/145 - Loss: 0.0136\n",
      "[Epoch 1/10] Step 130/145 - Loss: 0.0130\n",
      "[Epoch 1/10] Step 140/145 - Loss: 0.0148\n",
      "🔁 Epoch 1 finished. Avg Train Loss: 0.0531\n",
      "🔁 Starting epoch 2/10\n",
      "[Epoch 2/10] Step 0/145 - Loss: 0.0141\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, train_loader, val_loader, device, optimizer, criterion, num_epochs, scheduler, log_interval)\u001b[0m\n\u001b[0;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 37\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m log_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loop(model, train_loader, log_interval=10, num_epochs=10, optimizer=optimizer, criterion=criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
