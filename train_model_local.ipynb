{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5633ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 parquet files â†’ 6126272 rows\n",
      "Kept 61 sessions longer than 3 days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.train import train_loop, test_loop\n",
    "from src.model import CNNLSTMModel\n",
    "from src.dataset import InverterTimeSeriesDataset\n",
    "from src.preprocess import *\n",
    "from src.visualize import *\n",
    "import torch\n",
    "\n",
    "inverter_data = load_parquet_data('data/inverter_data')\n",
    "failure_sessions = load_failure_sessions('data/failure_sessions.csv', min_days=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11fb3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_time_gaps(df: pd.DataFrame,\n",
    "                   time_col: str = \"event_local_time\",\n",
    "                   device_col: str | None = \"device_name\",\n",
    "                   freq: str = \"5min\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "\n",
    "    expected = pd.to_timedelta(freq)\n",
    "    expected_min = expected / pd.Timedelta(minutes=1)\n",
    "\n",
    "    def _calc(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = g.sort_values(time_col)\n",
    "        if len(g) < 2:\n",
    "            return pd.DataFrame(columns=[\"prev_time\",\"curr_time\",\"gap_minutes\",\"gap_type\",\n",
    "                                         \"expected_minutes\",\"missing_points_estimate\"])\n",
    "        diff = g[time_col].diff()\n",
    "\n",
    "        out = pd.DataFrame({\n",
    "            \"prev_time\": g[time_col].shift(1),\n",
    "            \"curr_time\": g[time_col],\n",
    "            \"gap_minutes\": diff / pd.Timedelta(minutes=1)\n",
    "        }).iloc[1:]  # ç¬¬ä¸€åˆ—ç„¡å‰ä¸€ç­†\n",
    "\n",
    "        gm = out[\"gap_minutes\"]\n",
    "\n",
    "        cond_missing  = gm >  expected_min\n",
    "        cond_duplicate = gm == 0\n",
    "        cond_overlap   = (gm < expected_min) & (gm > 0)  # æ¯”é æœŸæ›´å¯†\n",
    "        cond_outorder  = gm < 0                          # å€’é€€ï¼ˆç†æ‡‰ä¸æœƒå‡ºç¾åœ¨å·²æ’åºï¼Œä½†ä¿éšªï¼‰\n",
    "\n",
    "        # ä¾å„ªå…ˆåºæ¨™è¨˜ï¼ˆç¼ºå£ > å€’é€€/éå¯† > é‡è¤‡ï¼‰\n",
    "        gap_type = np.where(cond_missing, \"missing\",\n",
    "                    np.where(cond_outorder | cond_overlap, \"overlap_or_out_of_order\",\n",
    "                    np.where(cond_duplicate, \"duplicate\", \"ok\")))\n",
    "\n",
    "        out[\"gap_type\"] = gap_type\n",
    "        out = out[out[\"gap_type\"] != \"ok\"]\n",
    "\n",
    "        out[\"expected_minutes\"] = float(expected_min)\n",
    "        out[\"missing_points_estimate\"] = np.where(\n",
    "            out[\"gap_type\"] == \"missing\",\n",
    "            (out[\"gap_minutes\"] / expected_min - 1).round().astype(int),\n",
    "            0\n",
    "        )\n",
    "        return out\n",
    "\n",
    "    if device_col and device_col in df.columns:\n",
    "        parts = []\n",
    "        for dev, g in df.groupby(device_col, sort=False):\n",
    "            tmp = _calc(g)\n",
    "            if not tmp.empty:\n",
    "                tmp.insert(0, device_col, dev)\n",
    "            parts.append(tmp)\n",
    "        gaps = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "    else:\n",
    "        gaps = _calc(df)\n",
    "\n",
    "    return gaps\n",
    "\n",
    "\n",
    "def is_continuous(df: pd.DataFrame,\n",
    "                  time_col: str = \"event_local_time\",\n",
    "                  device_col: str | None = \"device_name\",\n",
    "                  freq: str = \"5min\") -> bool:\n",
    "    return find_time_gaps(df, time_col=time_col, device_col=device_col, freq=freq).empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c990a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_gap = find_time_gaps(inverter_data, time_col='event_local_time', device_col='device_name', freq='5min')\n",
    "time_gap.to_csv('data/time_gap.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ac0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important parameters\n",
    "pre_day = 30\n",
    "window_size = 12*24 # 5 minutes * 12 * 24 = 1 day\n",
    "stride = 12 # 1 hour stride\n",
    "\n",
    "feature_cols = [\n",
    "    #\"metric.STATUS_AC_MOD_ADMISSION_TEMP.MEASURED\",  # ambient temperature\n",
    "    #\"metric.STATUS_INTERNAL_TEMP.MEASURED\",          # internal temperature\n",
    "    \"metric.AC_VOLTAGE_AB.MEASURED\",                 # AC voltage\n",
    "    \"metric.AC_VOLTAGE_BC.MEASURED\",                 # AC voltage\n",
    "    \"metric.AC_VOLTAGE_CA.MEASURED\",                 # AC voltage\n",
    "    \"metric.DC_VOLTAGE.MEASURED\"                     # DC voltage\n",
    "]\n",
    "\n",
    "exclude_periods = [\n",
    "    [pd.Timestamp('2021-01-01'), pd.Timestamp('2021-12-23')], # data collection issue\n",
    "    [pd.Timestamp('2023-02-23'), pd.Timestamp('2023-08-26')] # anomalies in the data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_hourly_mean_values(inverter_data, failure_sessions, feature_cols, 'visualization/raw_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de9395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverter_data shape: (6126272, 59)\n",
      "Excluded data shape: (5172608, 59)\n"
     ]
    }
   ],
   "source": [
    "print(\"inverter_data shape:\", inverter_data.shape)\n",
    "excluded_data = exclude_periods_from_data(inverter_data, exclude_periods)\n",
    "print(\"Excluded data shape:\", excluded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abe8c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = excluded_data[['event_local_time', 'device_name'] + feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ad6261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved for device: INV 51 at visualization/filtered_data//INV 51.html\n",
      "Visualization saved for device: INV 52 at visualization/filtered_data//INV 52.html\n",
      "Visualization saved for device: INV 53 at visualization/filtered_data//INV 53.html\n",
      "Visualization saved for device: INV 54 at visualization/filtered_data//INV 54.html\n",
      "Visualization saved for device: INV 55 at visualization/filtered_data//INV 55.html\n",
      "Visualization saved for device: INV 56 at visualization/filtered_data//INV 56.html\n",
      "Visualization saved for device: INV 57 at visualization/filtered_data//INV 57.html\n",
      "Visualization saved for device: INV 58 at visualization/filtered_data//INV 58.html\n",
      "Visualization saved for device: INV 59 at visualization/filtered_data//INV 59.html\n",
      "Visualization saved for device: INV 60 at visualization/filtered_data//INV 60.html\n",
      "Visualization saved for device: INV 61 at visualization/filtered_data//INV 61.html\n",
      "Visualization saved for device: INV 62 at visualization/filtered_data//INV 62.html\n",
      "Visualization saved for device: INV 63 at visualization/filtered_data//INV 63.html\n",
      "Visualization saved for device: INV 64 at visualization/filtered_data//INV 64.html\n",
      "Visualization saved for device: INV 65 at visualization/filtered_data//INV 65.html\n",
      "Visualization saved for device: INV 66 at visualization/filtered_data//INV 66.html\n"
     ]
    }
   ],
   "source": [
    "visualize_hourly_mean_values(selected_data, failure_sessions, feature_cols, 'visualization/filtered_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262cba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pre-failure rows: 365836\n",
      "Total rows: 5026798\n"
     ]
    }
   ],
   "source": [
    "labeled_df = prepare_dataset(selected_data, failure_sessions, pre_days=pre_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74fb2cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_missing_value_mask(df: pd.DataFrame, features_cols: list[str]) -> pd.DataFrame:\n",
    "    # Step 1: ç¼ºå¤± mask\n",
    "    for col in features_cols:\n",
    "        df[f\"{col}_missing\"] = df[col].isna().astype(int)\n",
    "        \n",
    "generate_missing_value_mask(labeled_df, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c4cb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def missing_value_imputation(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    time_col: str = \"event_local_time\",\n",
    "    device_col: str = \"device_name\",\n",
    "    short_gap_limit: int = 6,   # 5 åˆ†é˜è³‡æ–™ -> 6 ç­† â‰ˆ 30 åˆ†é˜å…§ç”¨æ’å€¼\n",
    "    long_fill_value: float = 0.0,\n",
    "    add_missing_mask: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    é‡å°å¤šè£ç½®æ™‚é–“åºåˆ—åšç¼ºå¤±è£œå€¼ï¼š\n",
    "      1) å…ˆç”¢ç”Ÿ per-step ç¼ºå¤± maskï¼ˆå¯é¸ï¼‰\n",
    "      2) æ¯å€‹è£ç½®å…§ï¼Œä»¥æ™‚é–“æ’åºå¾Œå° feature åšã€Œæ™‚é–“å‹æ’å€¼ã€(limit=short_gap_limit)\n",
    "      3) å°šæœªè£œåˆ°çš„é•·ç¼ºå¤±ä»¥æŒ‡å®šå€¼ï¼ˆé è¨­ 0ï¼‰è£œé½Š\n",
    "\n",
    "    åƒæ•¸ï¼š\n",
    "      - df: åŸå§‹ DataFrameï¼Œéœ€åŒ…å« time_col èˆ‡ device_col\n",
    "      - feature_cols: è¦è£œå€¼çš„æ•¸å€¼æ¬„ä½\n",
    "      - time_col: æ™‚é–“æ¬„ä½åç¨±ï¼ˆéœ€å¯è½‰ç‚º datetimeï¼‰\n",
    "      - device_col: è£ç½®æ¬„ä½åç¨±\n",
    "      - short_gap_limit: é€£çºŒç¼ºå¤±ç­†æ•¸åœ¨æ­¤ä¸Šé™ä»¥å…§ä½¿ç”¨æ’å€¼\n",
    "      - long_fill_value: æ’å€¼å¾Œä»ç‚º NaN çš„é•·ç¼ºå¤±ä»¥æ­¤å€¼è£œ\n",
    "      - add_missing_mask: æ˜¯å¦ç‚ºæ¯å€‹ feature ç”¢ç”Ÿ *_missing çš„ 0/1 mask æ¬„ä½\n",
    "\n",
    "    å›å‚³ï¼š\n",
    "      - å®Œæˆè£œå€¼èˆ‡ï¼ˆå¯é¸ï¼‰æ–°å¢ mask çš„ DataFrame\n",
    "    \"\"\"\n",
    "    imputed_df = df.copy()\n",
    "\n",
    "    # ç¢ºä¿æ™‚é–“æ¬„ç‚º datetime\n",
    "    imputed_df[time_col] = pd.to_datetime(imputed_df[time_col], errors=\"coerce\")\n",
    "\n",
    "    # éœ€è¦çš„æ¬„ä½å­˜åœ¨æ€§æª¢æŸ¥\n",
    "    missing_cols = [c for c in [time_col, device_col] + feature_cols if c not in imputed_df.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"Columns not found in df: {missing_cols}\")\n",
    "\n",
    "    for device, device_data in imputed_df.groupby(device_col, sort=False):\n",
    "        # è¤‡è£½é¿å… SettingWithCopy\n",
    "        block = device_data.loc[:, [time_col, device_col] + feature_cols].copy()\n",
    "        # è¨˜ä½åŸå§‹ç´¢å¼•ä»¥ä¾¿æ”¾å›\n",
    "        block[\"_orig_idx\"] = block.index\n",
    "\n",
    "        # ç”¢ç”Ÿ per-step ç¼ºå¤± maskï¼ˆåŸºæ–¼åŸå§‹ç¼ºå¤±ï¼‰\n",
    "        if add_missing_mask:\n",
    "            for col in feature_cols:\n",
    "                imputed_df.loc[block[\"_orig_idx\"], f\"{col}_missing\"] = block[col].isna().astype(int)\n",
    "\n",
    "        # ä¾æ™‚é–“æ’åºä¸¦ä»¥æ™‚é–“ç‚ºç´¢å¼•åš time-based interpolate\n",
    "        block = block.sort_values(time_col)\n",
    "        block = block.set_index(time_col)\n",
    "\n",
    "        # åƒ…å°ç›®æ¨™ç‰¹å¾µåšè™•ç†\n",
    "        # çŸ­ç¼ºå¤±ï¼šæ™‚é–“æ’å€¼ï¼ˆé›™å‘çš†å¯ï¼Œé¿å…å‰æ®µæˆ–å°¾æ®µå…¨ NaN ç„¡æ³•è£œï¼‰\n",
    "        block[feature_cols] = block[feature_cols].interpolate(\n",
    "            method=\"time\", limit=short_gap_limit\n",
    "        ).interpolate(method=\"time\", limit_direction=\"both\")\n",
    "\n",
    "        # é•·ç¼ºå¤±ï¼šä»ç‚º NaN çš„ä»¥æŒ‡å®šå€¼è£œé½Š\n",
    "        block[feature_cols] = block[feature_cols].fillna(long_fill_value)\n",
    "\n",
    "        # é‚„åŸç´¢å¼•èˆ‡é †åº\n",
    "        block = block.reset_index()\n",
    "        block = block.set_index(\"_orig_idx\").sort_index()\n",
    "\n",
    "        # å¯«å› imputed_dfï¼ˆåƒ…è¦†è“‹ç›®æ¨™ç‰¹å¾µæ¬„ï¼‰\n",
    "        imputed_df.loc[block.index, feature_cols] = block[feature_cols].values\n",
    "\n",
    "    return imputed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6b1d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = missing_value_imputation(labeled_df, feature_cols, time_col='event_local_time', device_col='device_name', short_gap_limit=6, long_fill_value=0.0, add_missing_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e26fda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 4021439 Train set time range: 2021-12-24 00:00:00 to 2024-12-04 04:10:00\n",
      "Test set size: 1005359 Test set time range: 2024-12-04 04:10:00 to 2025-07-23 23:35:00\n",
      "Train set size: 502680 Train set time range: 2024-12-04 04:10:00 to 2025-03-23 07:15:00\n",
      "Test set size: 502679 Test set time range: 2025-03-23 07:15:00 to 2025-07-23 23:35:00\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split_on_time(imputed_df, 0.2)\n",
    "val_df, test_df = train_test_split_on_time(test_df, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cbde8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
    "val_df[feature_cols] = scaler.transform(val_df[feature_cols])\n",
    "test_df[feature_cols] = scaler.transform(test_df[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8d6baea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_local_time', 'device_name', 'metric.AC_VOLTAGE_AB.MEASURED',\n",
       "       'metric.AC_VOLTAGE_BC.MEASURED', 'metric.AC_VOLTAGE_CA.MEASURED',\n",
       "       'metric.DC_VOLTAGE.MEASURED', 'label',\n",
       "       'metric.AC_VOLTAGE_AB.MEASURED_missing',\n",
       "       'metric.AC_VOLTAGE_BC.MEASURED_missing',\n",
       "       'metric.AC_VOLTAGE_CA.MEASURED_missing',\n",
       "       'metric.DC_VOLTAGE.MEASURED_missing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bd695259",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = feature_cols+[col+'_missing' for col in feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "57cba54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['metric.AC_VOLTAGE_AB.MEASURED',\n",
       " 'metric.AC_VOLTAGE_BC.MEASURED',\n",
       " 'metric.AC_VOLTAGE_CA.MEASURED',\n",
       " 'metric.DC_VOLTAGE.MEASURED',\n",
       " 'metric.AC_VOLTAGE_AB.MEASURED_missing',\n",
       " 'metric.AC_VOLTAGE_BC.MEASURED_missing',\n",
       " 'metric.AC_VOLTAGE_CA.MEASURED_missing',\n",
       " 'metric.DC_VOLTAGE.MEASURED_missing']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved for device: INV 51 at visualization/train_data//INV 51.html\n",
      "Visualization saved for device: INV 59 at visualization/train_data//INV 59.html\n",
      "Visualization saved for device: INV 64 at visualization/train_data//INV 64.html\n",
      "Visualization saved for device: INV 62 at visualization/train_data//INV 62.html\n",
      "Visualization saved for device: INV 52 at visualization/train_data//INV 52.html\n",
      "Visualization saved for device: INV 53 at visualization/train_data//INV 53.html\n",
      "Visualization saved for device: INV 60 at visualization/train_data//INV 60.html\n",
      "Visualization saved for device: INV 66 at visualization/train_data//INV 66.html\n",
      "Visualization saved for device: INV 58 at visualization/train_data//INV 58.html\n",
      "Visualization saved for device: INV 57 at visualization/train_data//INV 57.html\n",
      "Visualization saved for device: INV 55 at visualization/train_data//INV 55.html\n",
      "Visualization saved for device: INV 65 at visualization/train_data//INV 65.html\n",
      "Visualization saved for device: INV 56 at visualization/train_data//INV 56.html\n",
      "Visualization saved for device: INV 54 at visualization/train_data//INV 54.html\n",
      "Visualization saved for device: INV 61 at visualization/train_data//INV 61.html\n",
      "Visualization saved for device: INV 63 at visualization/train_data//INV 63.html\n"
     ]
    }
   ],
   "source": [
    "visualize_hourly_mean_values(train_df, failure_sessions, feature_cols, 'visualization/train_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89be8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing devices: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  9.17it/s]\n",
      "Processing devices: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 48.40it/s]\n",
      "Processing devices: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 47.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = InverterTimeSeriesDataset(train_df, feature_cols, under_sample=True, window_size=window_size, stride=stride)\n",
    "val_ds   = InverterTimeSeriesDataset(val_df,   feature_cols, window_size=window_size, stride=stride)\n",
    "test_ds  = InverterTimeSeriesDataset(test_df,  feature_cols, window_size=window_size, stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e127b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44806, 288, 8])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc679b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0    22403\n",
       " 1.0    22403\n",
       " dtype: int64,\n",
       " 0.0    40208\n",
       " 1.0      928\n",
       " dtype: int64,\n",
       " 0.0    34432\n",
       " 1.0     6780\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train_ds.y.numpy()), pd.value_counts(val_ds.y.numpy()), pd.value_counts(test_ds.y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b204cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2**10\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=6, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac4316e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTMModel(num_features=len(feature_cols), cnn_out_channels=64, lstm_hidden_size=128)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "59c807ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to cuda\n",
      "[Epoch 1/10] Step 0/44 - Loss: 0.2505\n",
      "[Epoch 1/10] Step 10/44 - Loss: 0.2401\n",
      "[Epoch 1/10] Step 20/44 - Loss: 0.2394\n",
      "[Epoch 1/10] Step 30/44 - Loss: 0.2402\n",
      "[Epoch 1/10] Step 40/44 - Loss: 0.2360\n",
      "ğŸ” Epoch 1 finished. Avg Train Loss: 0.2408\n",
      "âœ… Validation Loss: 0.1792 | Accuracy: 65.78%\n",
      "[Epoch 2/10] Step 0/44 - Loss: 0.2401\n",
      "[Epoch 2/10] Step 10/44 - Loss: 0.2313\n",
      "[Epoch 2/10] Step 20/44 - Loss: 0.2364\n",
      "[Epoch 2/10] Step 30/44 - Loss: 0.2370\n",
      "[Epoch 2/10] Step 40/44 - Loss: 0.2634\n",
      "ğŸ” Epoch 2 finished. Avg Train Loss: 0.2383\n",
      "âœ… Validation Loss: 0.1132 | Accuracy: 90.33%\n",
      "[Epoch 3/10] Step 0/44 - Loss: 0.2444\n",
      "[Epoch 3/10] Step 10/44 - Loss: 0.2349\n",
      "[Epoch 3/10] Step 20/44 - Loss: 0.2359\n",
      "[Epoch 3/10] Step 30/44 - Loss: 0.2443\n",
      "[Epoch 3/10] Step 40/44 - Loss: 0.2317\n",
      "ğŸ” Epoch 3 finished. Avg Train Loss: 0.2360\n",
      "âœ… Validation Loss: 0.1835 | Accuracy: 72.35%\n",
      "[Epoch 4/10] Step 0/44 - Loss: 0.2341\n",
      "[Epoch 4/10] Step 10/44 - Loss: 0.2313\n",
      "[Epoch 4/10] Step 20/44 - Loss: 0.2261\n",
      "[Epoch 4/10] Step 30/44 - Loss: 0.2304\n",
      "[Epoch 4/10] Step 40/44 - Loss: 0.2257\n",
      "ğŸ” Epoch 4 finished. Avg Train Loss: 0.2281\n",
      "âœ… Validation Loss: 0.1550 | Accuracy: 76.47%\n",
      "[Epoch 5/10] Step 0/44 - Loss: 0.2211\n",
      "[Epoch 5/10] Step 10/44 - Loss: 0.2303\n",
      "[Epoch 5/10] Step 20/44 - Loss: 0.2198\n",
      "[Epoch 5/10] Step 30/44 - Loss: 0.2263\n",
      "[Epoch 5/10] Step 40/44 - Loss: 0.2197\n",
      "ğŸ” Epoch 5 finished. Avg Train Loss: 0.2227\n",
      "âœ… Validation Loss: 0.1456 | Accuracy: 79.84%\n",
      "[Epoch 6/10] Step 0/44 - Loss: 0.2231\n",
      "[Epoch 6/10] Step 10/44 - Loss: 0.2215\n",
      "[Epoch 6/10] Step 20/44 - Loss: 0.2178\n",
      "[Epoch 6/10] Step 30/44 - Loss: 0.2181\n",
      "[Epoch 6/10] Step 40/44 - Loss: 0.2236\n",
      "ğŸ” Epoch 6 finished. Avg Train Loss: 0.2211\n",
      "âœ… Validation Loss: 0.1449 | Accuracy: 81.78%\n",
      "[Epoch 7/10] Step 0/44 - Loss: 0.2225\n",
      "[Epoch 7/10] Step 10/44 - Loss: 0.2194\n",
      "[Epoch 7/10] Step 20/44 - Loss: 0.2191\n",
      "[Epoch 7/10] Step 30/44 - Loss: 0.2236\n",
      "[Epoch 7/10] Step 40/44 - Loss: 0.2330\n",
      "ğŸ” Epoch 7 finished. Avg Train Loss: 0.2221\n",
      "âœ… Validation Loss: 0.1616 | Accuracy: 77.12%\n",
      "[Epoch 8/10] Step 0/44 - Loss: 0.2223\n",
      "[Epoch 8/10] Step 10/44 - Loss: 0.2255\n",
      "[Epoch 8/10] Step 20/44 - Loss: 0.2224\n",
      "[Epoch 8/10] Step 30/44 - Loss: 0.2332\n",
      "[Epoch 8/10] Step 40/44 - Loss: 0.2305\n",
      "ğŸ” Epoch 8 finished. Avg Train Loss: 0.2284\n",
      "âœ… Validation Loss: 0.1871 | Accuracy: 51.07%\n",
      "[Epoch 9/10] Step 0/44 - Loss: 0.2347\n",
      "[Epoch 9/10] Step 10/44 - Loss: 0.2296\n",
      "[Epoch 9/10] Step 20/44 - Loss: 0.2329\n",
      "[Epoch 9/10] Step 30/44 - Loss: 0.2187\n",
      "[Epoch 9/10] Step 40/44 - Loss: 0.2253\n",
      "ğŸ” Epoch 9 finished. Avg Train Loss: 0.2267\n",
      "âœ… Validation Loss: 0.1463 | Accuracy: 85.31%\n",
      "[Epoch 10/10] Step 0/44 - Loss: 0.2208\n",
      "[Epoch 10/10] Step 10/44 - Loss: 0.2208\n",
      "[Epoch 10/10] Step 20/44 - Loss: 0.2239\n",
      "[Epoch 10/10] Step 30/44 - Loss: 0.2264\n",
      "[Epoch 10/10] Step 40/44 - Loss: 0.2212\n",
      "ğŸ” Epoch 10 finished. Avg Train Loss: 0.2230\n",
      "âœ… Validation Loss: 0.1743 | Accuracy: 74.27%\n",
      "ğŸ Training completed.\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, train_loader, val_loader, log_interval=10, num_epochs=10, optimizer=optimizer, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b87c94d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to cuda\n",
      "[Epoch 1/10] Step 0/44 - Loss: 0.2199\n",
      "[Epoch 1/10] Step 10/44 - Loss: 0.2196\n",
      "[Epoch 1/10] Step 20/44 - Loss: 0.2184\n",
      "[Epoch 1/10] Step 30/44 - Loss: 0.2258\n",
      "[Epoch 1/10] Step 40/44 - Loss: 0.2263\n",
      "ğŸ” Epoch 1 finished. Avg Train Loss: 0.2218\n",
      "âœ… Validation Loss: 0.1751 | Accuracy: 72.38%\n",
      "[Epoch 2/10] Step 0/44 - Loss: 0.2257\n",
      "[Epoch 2/10] Step 10/44 - Loss: 0.2180\n",
      "[Epoch 2/10] Step 20/44 - Loss: 0.2349\n",
      "[Epoch 2/10] Step 30/44 - Loss: 0.2206\n",
      "[Epoch 2/10] Step 40/44 - Loss: 0.2181\n",
      "ğŸ” Epoch 2 finished. Avg Train Loss: 0.2220\n",
      "âœ… Validation Loss: 0.1617 | Accuracy: 76.04%\n",
      "[Epoch 3/10] Step 0/44 - Loss: 0.2303\n",
      "[Epoch 3/10] Step 10/44 - Loss: 0.2072\n",
      "[Epoch 3/10] Step 20/44 - Loss: 0.2188\n",
      "[Epoch 3/10] Step 30/44 - Loss: 0.2208\n",
      "[Epoch 3/10] Step 40/44 - Loss: 0.2165\n",
      "ğŸ” Epoch 3 finished. Avg Train Loss: 0.2176\n",
      "âœ… Validation Loss: 0.1947 | Accuracy: 62.65%\n",
      "[Epoch 4/10] Step 0/44 - Loss: 0.2300\n",
      "[Epoch 4/10] Step 10/44 - Loss: 0.2187\n",
      "[Epoch 4/10] Step 20/44 - Loss: 0.2287\n",
      "[Epoch 4/10] Step 30/44 - Loss: 0.2227\n",
      "[Epoch 4/10] Step 40/44 - Loss: 0.2231\n",
      "ğŸ” Epoch 4 finished. Avg Train Loss: 0.2237\n",
      "âœ… Validation Loss: 0.1586 | Accuracy: 75.46%\n",
      "[Epoch 5/10] Step 0/44 - Loss: 0.2171\n",
      "[Epoch 5/10] Step 10/44 - Loss: 0.2255\n",
      "[Epoch 5/10] Step 20/44 - Loss: 0.2212\n",
      "[Epoch 5/10] Step 30/44 - Loss: 0.2179\n",
      "[Epoch 5/10] Step 40/44 - Loss: 0.2190\n",
      "ğŸ” Epoch 5 finished. Avg Train Loss: 0.2201\n",
      "âœ… Validation Loss: 0.1465 | Accuracy: 96.49%\n",
      "[Epoch 6/10] Step 0/44 - Loss: 0.2153\n",
      "[Epoch 6/10] Step 10/44 - Loss: 0.2186\n",
      "[Epoch 6/10] Step 20/44 - Loss: 0.2222\n",
      "[Epoch 6/10] Step 30/44 - Loss: 0.2182\n",
      "[Epoch 6/10] Step 40/44 - Loss: 0.2190\n",
      "ğŸ” Epoch 6 finished. Avg Train Loss: 0.2173\n",
      "âœ… Validation Loss: 0.1364 | Accuracy: 91.55%\n",
      "[Epoch 7/10] Step 0/44 - Loss: 0.2130\n",
      "[Epoch 7/10] Step 10/44 - Loss: 0.2188\n",
      "[Epoch 7/10] Step 20/44 - Loss: 0.2095\n",
      "[Epoch 7/10] Step 30/44 - Loss: 0.2145\n",
      "[Epoch 7/10] Step 40/44 - Loss: 0.2122\n",
      "ğŸ” Epoch 7 finished. Avg Train Loss: 0.2163\n",
      "âœ… Validation Loss: 0.1464 | Accuracy: 74.76%\n",
      "[Epoch 8/10] Step 0/44 - Loss: 0.2102\n",
      "[Epoch 8/10] Step 10/44 - Loss: 0.2157\n",
      "[Epoch 8/10] Step 20/44 - Loss: 0.2132\n",
      "[Epoch 8/10] Step 30/44 - Loss: 0.2128\n",
      "[Epoch 8/10] Step 40/44 - Loss: 0.2209\n",
      "ğŸ” Epoch 8 finished. Avg Train Loss: 0.2147\n",
      "âœ… Validation Loss: 0.1410 | Accuracy: 82.46%\n",
      "[Epoch 9/10] Step 0/44 - Loss: 0.2139\n",
      "[Epoch 9/10] Step 10/44 - Loss: 0.2132\n",
      "[Epoch 9/10] Step 20/44 - Loss: 0.2138\n",
      "[Epoch 9/10] Step 30/44 - Loss: 0.2193\n",
      "[Epoch 9/10] Step 40/44 - Loss: 0.2312\n",
      "ğŸ” Epoch 9 finished. Avg Train Loss: 0.2172\n",
      "âœ… Validation Loss: 0.1741 | Accuracy: 67.22%\n",
      "[Epoch 10/10] Step 0/44 - Loss: 0.2324\n",
      "[Epoch 10/10] Step 10/44 - Loss: 0.2326\n",
      "[Epoch 10/10] Step 20/44 - Loss: 0.2327\n",
      "[Epoch 10/10] Step 30/44 - Loss: 0.2355\n",
      "[Epoch 10/10] Step 40/44 - Loss: 0.2331\n",
      "ğŸ” Epoch 10 finished. Avg Train Loss: 0.2334\n",
      "âœ… Validation Loss: 0.1631 | Accuracy: 70.25%\n",
      "ğŸ Training completed.\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, train_loader, val_loader, log_interval=10, num_epochs=10, optimizer=optimizer, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6f6469ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/20_epochs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1903787d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMModel(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv1d(8, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (lstm): LSTM(64, 128, batch_first=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = CNNLSTMModel(num_features=len(feature_cols), cnn_out_channels=64, lstm_hidden_size=128)\n",
    "loaded_model.load_state_dict(torch.load('model/20_epochs.pth'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "091d46f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Test Loss: 0.2453 | Accuracy: 48.57%\n"
     ]
    }
   ],
   "source": [
    "trues, predictions = test_loop(model, test_loader, device='cuda', criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "af1c98a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.85      0.47      0.60     34432\n",
      "     Failure       0.17      0.57      0.27      6780\n",
      "\n",
      "    accuracy                           0.49     41212\n",
      "   macro avg       0.51      0.52      0.44     41212\n",
      "weighted avg       0.74      0.49      0.55     41212\n",
      "\n",
      "[[16143 18289]\n",
      " [ 2908  3872]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(trues, predictions , target_names=['Normal', 'Failure']))\n",
    "print(confusion_matrix(trues, predictions ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
